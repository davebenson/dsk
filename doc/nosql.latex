\documentclass{article}
\title{Scalable Key-Value Data-Structures}
\author{David Benson}
\frenchspacing
\usepackage{amsfonts,amsmath,amssymb,epsfig,eucal}
\pagestyle{headings}
\begin{document}
\maketitle

\section{Overview}

\subsection{Goals}
\begin{itemize}
\item zero-conf: ... trivial administration
\item cloudish backup strategy:
\item easy to use data-structures:
\item fast
\end{itemize}

\section{Data Types Supported}
\subsection{String}
A string is our convenient name for ``binary data'' -- we treat the data as opaque.  It
is not necessarily character-data -- for example, it need not be valid UTF-8.

When string values are set, the one with the greatest timestamp wins (ie assumes the value).

Deletion tombstones (that is, markers for preserving deletion status) also have timestamps.
The difference is that tombstones may be removed if the deletion is old enough.

Here are the operations on a string:

\begin{tabular}{lp{3in}}
{\bf operation} & {\bf description} \\
{\tt ASSIGN} & set the value of the string \\
{\tt LADD} & prepend to (or create) \\
{\tt RADD} & append to (or create) \\
{\tt DELETE} & delete the entry 
\end{tabular}


\subsection{List}
This is a two-ended list.  Duplicate entries are permitted.  Operations:

\begin{tabular}{lp{3in}}
{\bf operation} & {\bf description} \\
{\tt LPUSH} & insert entry on left-end of list \\
{\tt RPUSH} & insert entry on right-end of list \\
{\tt LPOP} & remove left-most entry from list \\
{\tt RPOP} & remove right-most entry from list \\
{\tt LTRIM} & keep the $N$ leftmost elements, delete the rest \\
{\tt RTRIM} & keep the $N$ rightmost elements, delete the rest \\
{\tt LREMOVE} & remove matching entry, starting at left \\
{\tt RREMOVE} & remove matching entry, starting at right \\
{\tt REMOVE\_ALL} & remove all matching entries \\
{\tt ASSIGN} & set the entire list \\
{\tt DELETE} & delete the entry 
\end{tabular}

\subsection{Map}
This is a string-to-string map.

\subsection{Set}
...
\subsection{ScoredSet}

\subsection{BigSet}
...
\subsection{BigScoredSet}
...
\subsection{BigList???}
...

\subsubsection{Allocating Index Strings???}
has this been researched?
what is a good way to allocate IDs with the following methods:
\begin{verbatim}
  alloc_id_between(PREV, NEXT)
\end{verbatim}
where there are special tokens called {\tt FIRST} and {\tt LAST} that can be used for
{\tt prev} and {\tt next} respectively, to mean ``no limit''.

I guess easily proven that for any partitioning scheme,
there exists some set of $N$ choices of adjacent {\tt PREV}/{\tt NEXT} tokens that leads
a string $N/8$ long.  This mostly means that we 

\section{Sort-Merge Tables}
\subsection{Deletion}
describe tombstones

also, if a node is no longer responsible for a bucket, we will filter it out whenever possible.
hmm, how will we distinguish buckets that are removed and readded?  answer: for each bucket, we need to know the max-age of the thing (which we can just use the file id for, since that's ascending...).
\subsection{Tuning}
\begin{itemize}
\item compression
 \begin{itemize}
 \item generic chunkwise compression (zlib, snappy)
 \item prefix compression
 \end{itemize}
\item index-spread
\item CPU v space
\end{itemize}

\section{Robustly Updatable Objects}
In all cases, the objects (ie the binary values stored) consist of a optional timestamped
core, plus a sequence of timestamped updates.  The update timestamps are allocated
by the server that receives the update request.

When the update queue gets too long (it has a max length and a max age),
additional updates are accumulated into a new timestamped core (either updating the old core or
creating a fresh one).

Updates with the same timestamp and content are viewed as idempotent, that is, they are combined.
Updates to objects whose core is later than the update are dropped.

When reading an object, if two machines have different update sets than expected, the differences
are sent to the servers.

In pretty much all cases the updates match the update primitives.

\section{Implementing {\tt merge}}
This function takes two robust objects (above) and combines them into a new robust object.
A reduce phase follows that cuts down the number of object updates required.

{\bf Step 1}: {\it Reconciling the base objects (if any).}

If there are no base objects, the result of the merge also has no base object.

If there is only one base object, assuming that any updates from the non-base object that occurred
before the base object's timestamp should be discarded, and the only base object is THE base object.

If there are two base objects, take the later object, discard any updates before that timestamp.
All other updates are merged: they must have the same timestamp and t

{\bf Step 2}: {\it Merging the list of updates.}

{\bf Step 3}.  Use {\tt reduce} to limit the object size.

\section{Implementing {\tt reduce}}
Reduce has two purposes:
\begin{itemize}
\item to bound the size of updatable objects
\item to deliver a final object to the user
\end{itemize}

The general format of reduce takes a maximum number of updates and a
maximum age, and condenses early updates with the base object.

\section{Combining Local Stores into a Highly-Available Global Store}
We are use consistent hashing:  each node in the system takes responsibility for
a subset of the hash-buckets.

The client library should probably have a load-balancing option, but we distribute
the queries internally as best we can.  At minimum, have your clients connect to
a server at random.

When a node joins the cluster for the first time:
\begin{itemize}
\item the node connects to all existing nodes in the cluster,
getting the cluster information.
\item if there is a problem it drops the connection and returns an error.
\item it sends a message that it has joined, along with consistent hashing probe angles.
if it is restarting, it should also give information about when it stopped (ie the last update
timestamp in its journal.)

\end{itemize}

Anyway, the nodes in the cluster are densely connected with sockets
and they speak a protocol to handle the following situations:
\begin{itemize}
\item new node connected
\item query (on behalf of client)
\item update (on behalf of client)
\item transfer buckets - implemented via dump+filter.  use some sort of flow control to minimize incast.
\end{itemize}


\section{Handling Failed Nodes}
...

\section{Tuning Reliability Versus Latency}
...

\section{Multiple Datacenter Support}
...

\section{Administration}
...

\subsection{Backups}
...

\section{Appendix:  Data Formats}
...

\section{Appendix:  Node Protocol}
A client and another node connect via a similar protocol handshake.\footnote{
All integer formats are little-endian.

\begin{tabular}{|rrp{3in}|}
{\bf offset} & {\bf length} & {\bf description} \\
0 & 4 & length of message that follows \\
4 & 8 & magic: {\tt f1 88 64 73 6b 65 64 62} \\
12 & 4 & type: \begin{tabular}{rl} \\
                {\tt 0} & a recovered node \\
		{\tt 1} & a new node \\
		{\tt 2} & a client
	       \end{tabular} \\
\hline
\end{tabular}
}  Let's take the client first.


\subsection{Client Protocol}
In response to the handshake, the server sends an OK message.\footnote{...}

The client can issue requests;\footnote{
\begin{tabular}{|rrp{3in}|}
{\bf offset} & {\bf length} & {\bf description} \\
0 & 4 & length of message that follows \\
4 & 4 & request type: \begin{tabular}{rl} \\
                        {\tt 9111} & query \\
                        {\tt 9112} & update
		      \end{tabular} \\
8 & 8 & request-id (used to match requests and responses) \\
16 & 4 & flags: none defined yet \\
20 & variable & request-type specific payload \\
\hline
\end{tabular}
} and the server responds to them.\footnote{
\begin{tabular}{|rrp{3in}|}
{\bf offset} & {\bf length} & {\bf description} \\
0 & 4 & length of message that follows \\
4 & 4 & request type (matches request) \\
8 & 8 & request-id (matches request) \\
16 & 4 & flags \begin{tabular}{rl} \\
                 {\tt 1} & response is last message for given request
	       \end{tabular} \\
20 & variable & request-type specific payload \\
\hline
\end{tabular}
}

The client can {\tt query}\footnote{...} the database.
It has options for how many servers to wait for; however,
consistency should usually be guaranteed by the update/replication layers
(and the database will resolve conflicts without the client's involvement on every read, regardless of
the {\tt n\_replicas} value).  Usually, the response will be a simple value\footnote{...} or an uncomplicated not-found message\footnote{...}.  But a number of errors are also possible\footnote{...}.

The client can also do a {\tt modify}\footnote{...}
which is actually a combination of assignments
(ie operations that discard the previous value),
updates (differential updates), and deletions.
(Internally, they are both implemented as timestamped-updates,
in order to avoid race-conditions.)
In many cases, you can avoid waiting for responses, and the {\tt ignore\_response} flag
is passed through to the nodes that actually have the value.

\subsection{Node Protocol}


\end{document}
